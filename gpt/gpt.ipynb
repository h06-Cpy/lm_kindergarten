{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2df45a",
   "metadata": {},
   "source": [
    "# GPT\n",
    "\n",
    "https://arxiv.org/abs/1706.03762"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb39ed",
   "metadata": {},
   "source": [
    "# self attention(SA)\n",
    "\n",
    "1. 토큰 사이 중요도(연관성) 가중치를 계산하고 (쿼리-키 행렬 곱)\n",
    "2. 가중치 반영 (가중치와 밸류 행렬 곱)\n",
    "\n",
    "토큰끼리 가중치는 사실 원소 값이 다 달라야 하지만\n",
    "\n",
    "일단은 똑같은 가중치(=평균)라고 가정하고 계산해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2aaf4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6c5656",
   "metadata": {},
   "source": [
    "## 심플한 평균 가중치 구하기\n",
    "데이터 `x` 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a9ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.3596, -0.9152],\n",
       "         [ 0.6258,  0.0255],\n",
       "         [ 0.9545,  0.0643],\n",
       "         [ 0.3612,  1.1679],\n",
       "         [-1.3499, -0.5102],\n",
       "         [ 0.2360, -0.2398],\n",
       "         [-0.9211,  1.5433]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.2858,  0.9651],\n",
       "         [-2.0371,  0.4931],\n",
       "         [ 1.4870,  0.5910],\n",
       "         [ 0.1260, -1.5627],\n",
       "         [-1.1601, -0.3348],\n",
       "         [ 0.4478, -0.8016],\n",
       "         [ 1.5236,  2.5086]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 1.0101,  0.1215],\n",
       "         [ 0.1584,  1.1340],\n",
       "         [-1.1539, -0.2984],\n",
       "         [-0.5075, -0.9239],\n",
       "         [ 0.5467, -1.4948],\n",
       "         [-1.2057,  0.5718],\n",
       "         [-0.5974, -0.6937]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.3514, -0.2759],\n",
       "         [-1.5108,  2.1048],\n",
       "         [ 2.7630, -1.7465],\n",
       "         [ 1.4516, -1.5103],\n",
       "         [ 0.8212, -0.2115],\n",
       "         [ 0.7789,  1.5333],\n",
       "         [ 1.6097, -0.4032]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the following toy example:\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "print(x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5f0e0a",
   "metadata": {},
   "source": [
    "`x` 내 timestep끼리 (토큰끼리) 가중치(평균) 계산\n",
    "\n",
    "근데 auto-regressive로 할거라\n",
    "\n",
    "가중치 첫번째 행은 1번째 토큰만 평균 -> 1\n",
    "\n",
    "두번째 행은 1~2번째 토큰끼리 평균 -> 0.5 0.5\n",
    "\n",
    "세번째 행은 1~3번째 토큰끼리 평균 -> 1/3 1/3 1/3\n",
    "\n",
    "…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66c80f",
   "metadata": {},
   "source": [
    "### lower triangular matrix 만들기\n",
    "\n",
    "`torch.tril`: lower triangular matrix(하삼각행렬)을 만드는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67f56069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "tril"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a4598",
   "metadata": {},
   "source": [
    "### upper triangular 부분을 -inf로 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31f8c8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816338cb",
   "metadata": {},
   "source": [
    "### softmax로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f68c848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = F.softmax(wei, dim=-1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ca5a8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.8173,  0.4127],\n",
       "         [-0.1342,  0.4395],\n",
       "         [ 0.2711,  0.4774],\n",
       "         [ 0.2421,  0.0694],\n",
       "         [ 0.0084,  0.0020],\n",
       "         [ 0.0712, -0.1128],\n",
       "         [ 0.2527,  0.2149]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.1735, -0.0649],\n",
       "         [ 0.1685,  0.3348],\n",
       "         [-0.1621,  0.1765],\n",
       "         [-0.2312, -0.0436],\n",
       "         [-0.1015, -0.2855],\n",
       "         [-0.2593, -0.1630],\n",
       "         [-0.3015, -0.2293]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4985, -0.5395],\n",
       "         [ 0.4954,  0.3420],\n",
       "         [ 1.0623, -0.1802],\n",
       "         [ 1.1401, -0.4462],\n",
       "         [ 1.0870, -0.4071],\n",
       "         [ 1.0430, -0.1299],\n",
       "         [ 1.1138, -0.1641]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2621f051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1808, -0.0700],\n",
       "         [-0.3596, -0.9152]]),\n",
       " tensor([-0.0894, -0.4926]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 1\n",
    "\n",
    "x[0, :t+1], x[0, :t+1].mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ab782",
   "metadata": {},
   "source": [
    "## 평균이 아니라 가중치가 다르다면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5abd91bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3530, 0.6470, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4054, 0.5365, 0.0580, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2387, 0.6678, 0.0713, 0.0222, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0750, 0.1745, 0.7418, 0.0012, 0.0075, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1437, 0.1235, 0.1103, 0.2730, 0.1915, 0.1580, 0.0000, 0.0000],\n",
       "        [0.1410, 0.1429, 0.1199, 0.1503, 0.1610, 0.1463, 0.1386, 0.0000],\n",
       "        [0.0325, 0.0137, 0.0257, 0.5486, 0.0565, 0.0408, 0.2649, 0.0173]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "\n",
    "q = torch.randn((T,C))\n",
    "k = torch.randn((T,C))\n",
    "\n",
    "wei = q @ k.T\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "657bac56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700],\n",
       "         [-0.1688, -0.6168],\n",
       "         [-0.0833, -0.5179],\n",
       "         [-0.1312, -0.6247],\n",
       "         [ 0.4188, -0.1372],\n",
       "         [ 0.1670,  0.0404],\n",
       "         [ 0.0859, -0.0478],\n",
       "         [ 0.5525,  0.0294]],\n",
       "\n",
       "        [[ 1.3488, -0.1396],\n",
       "         [ 0.6611,  0.5751],\n",
       "         [ 0.5819,  0.4898],\n",
       "         [ 0.4006,  0.6595],\n",
       "         [-1.3573,  0.5128],\n",
       "         [ 0.2511, -0.0373],\n",
       "         [ 0.1228, -0.1454],\n",
       "         [ 0.9157,  0.0747]],\n",
       "\n",
       "        [[-0.6631, -0.2513],\n",
       "         [ 0.4194, -0.0101],\n",
       "         [ 0.2823,  0.0292],\n",
       "         [ 0.5020,  0.0954],\n",
       "         [ 0.2389,  0.8363],\n",
       "         [-0.2789, -0.3906],\n",
       "         [-0.2724, -0.2151],\n",
       "         [-0.9727, -0.1147]],\n",
       "\n",
       "        [[ 1.6455, -0.8030],\n",
       "         [ 1.4552, -0.4620],\n",
       "         [ 1.3045, -0.3514],\n",
       "         [ 1.2489, -0.2646],\n",
       "         [-0.7472,  1.4394],\n",
       "         [ 1.3987, -0.7167],\n",
       "         [ 1.1210, -0.2242],\n",
       "         [ 1.8984, -0.6285]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51ca6722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1808, -0.0700],\n",
       "         [-0.3596, -0.9152]]),\n",
       " tensor([-0.0894, -0.4926]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 1\n",
    "\n",
    "x[0, :t+1], x[0, :t+1].mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14d72b9",
   "metadata": {},
   "source": [
    "## 어텐션 헤드 구현\n",
    "\n",
    "scaled dot product attention 그림 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3f72f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700, -0.3596,  ..., -0.8016,  1.5236,  2.5086],\n",
       "         [-0.6631, -0.2513,  1.0101,  ...,  1.5333,  1.6097, -0.4032],\n",
       "         [-0.8345,  0.5978, -0.0514,  ..., -0.4370, -1.0012, -0.4094],\n",
       "         ...,\n",
       "         [-0.8961,  0.0662, -0.0563,  ...,  2.1382,  0.5114,  1.2191],\n",
       "         [ 0.1910, -0.3425,  1.7955,  ...,  0.3699, -0.5556, -0.3983],\n",
       "         [-0.5819, -0.2208,  0.0135,  ..., -1.9079, -0.5276,  1.0807]],\n",
       "\n",
       "        [[ 0.4562, -1.0917, -0.8207,  ...,  0.0512, -0.6576, -2.5729],\n",
       "         [ 0.0210,  1.0060, -1.2492,  ...,  0.7859, -1.1501,  1.3132],\n",
       "         [ 2.2007, -0.2195,  0.5427,  ..., -0.6445,  1.0834, -0.7995],\n",
       "         ...,\n",
       "         [ 0.3091,  1.1661, -2.1821,  ...,  0.6151,  0.6763,  0.6228],\n",
       "         [ 0.0943, -0.3156,  0.7850,  ..., -1.5735,  1.3876,  0.7251],\n",
       "         [ 0.6455, -0.3313, -1.0390,  ...,  0.0895, -0.3748, -0.4781]],\n",
       "\n",
       "        [[-0.6067,  1.8328,  0.2931,  ...,  1.0041,  0.8656,  0.1688],\n",
       "         [-0.2352, -0.2586,  0.0131,  ...,  0.6690,  0.7535, -0.5359],\n",
       "         [-1.0277,  0.5347, -0.7958,  ...,  1.0711,  0.4901, -0.4876],\n",
       "         ...,\n",
       "         [-0.6896, -0.7080, -0.3152,  ..., -2.0662, -1.1418, -0.1391],\n",
       "         [ 1.0827,  1.1522,  0.5198,  ...,  0.4970,  0.0585,  0.1033],\n",
       "         [ 0.0720,  1.1080,  0.7293,  ...,  0.3967, -0.9755,  0.5122]],\n",
       "\n",
       "        [[ 0.3330,  1.0995,  0.4034,  ...,  1.6634, -0.4718,  0.5857],\n",
       "         [-0.9579,  0.9435, -2.1992,  ..., -0.7296,  0.1653, -0.3390],\n",
       "         [ 1.5416,  1.0231,  1.3392,  ..., -0.0433, -0.2505, -0.7493],\n",
       "         ...,\n",
       "         [ 0.7450,  0.7170,  1.2668,  ...,  1.9359,  2.0350,  2.0187],\n",
       "         [ 0.0323, -0.6337,  0.2938,  ..., -0.3297, -0.0192,  0.9225],\n",
       "         [ 0.9187,  0.2998,  0.6106,  ...,  0.8282, -0.4826,  1.8330]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4, 8, 32 # batch time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f2f1169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see a single head perform self-attention\n",
    "head_dim = 16\n",
    "query = nn.Linear(C, head_dim, bias=False)\n",
    "key = nn.Linear(C, head_dim, bias=False)\n",
    "value = nn.Linear(C, head_dim, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8cfeba2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0470, 0.9530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1304, 0.2016, 0.6681, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0213, 0.0209, 0.5170, 0.4409, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6170, 0.0640, 0.1277, 0.0954, 0.0959, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3187, 0.3157, 0.0547, 0.0395, 0.0769, 0.1945, 0.0000, 0.0000],\n",
       "         [0.0040, 0.0097, 0.0285, 0.2566, 0.0422, 0.5379, 0.1211, 0.0000],\n",
       "         [0.0141, 0.0040, 0.0103, 0.1250, 0.0549, 0.0550, 0.0709, 0.6658]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0167, 0.9833, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3629, 0.5985, 0.0386, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0387, 0.0902, 0.2823, 0.5888, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1568, 0.0657, 0.5267, 0.0665, 0.1843, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0822, 0.0137, 0.5397, 0.0815, 0.0605, 0.2225, 0.0000, 0.0000],\n",
       "         [0.0941, 0.2264, 0.2443, 0.0801, 0.1648, 0.0550, 0.1353, 0.0000],\n",
       "         [0.8573, 0.0088, 0.0382, 0.0202, 0.0063, 0.0232, 0.0077, 0.0383]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1564, 0.8436, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1261, 0.7435, 0.1304, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2320, 0.1104, 0.2597, 0.3979, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0310, 0.3898, 0.0360, 0.0748, 0.4684, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2469, 0.2924, 0.0167, 0.1310, 0.1168, 0.1961, 0.0000, 0.0000],\n",
       "         [0.0496, 0.0989, 0.0951, 0.0515, 0.0216, 0.5387, 0.1446, 0.0000],\n",
       "         [0.0958, 0.0631, 0.0325, 0.2009, 0.0831, 0.1364, 0.1255, 0.2625]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0648, 0.9352, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3507, 0.0218, 0.6275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3478, 0.1754, 0.3494, 0.1274, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1367, 0.3396, 0.1149, 0.1163, 0.2925, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0969, 0.0027, 0.0601, 0.1304, 0.0024, 0.7076, 0.0000, 0.0000],\n",
       "         [0.0263, 0.3101, 0.0320, 0.0033, 0.4309, 0.1204, 0.0770, 0.0000],\n",
       "         [0.0099, 0.0034, 0.0071, 0.4040, 0.0649, 0.0787, 0.0362, 0.3957]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = query(x) # (B, T, 16)\n",
    "k = key(x) # (B, T, 16)\n",
    "v = value(x) # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1) # (B,T,16) @ (B,16,T) ---> (B,T,T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2b302f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = wei @ v # (B,T,T) @ (B,T,16) ---> (B,T,16)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad21198",
   "metadata": {},
   "source": [
    "## note 1: 어텐션은 communication mechanism\n",
    "\n",
    "timestep t까지 (1~t) 각 토큰끼리 \n",
    "\n",
    "- 정보를 aggregation하고 (쿼리-키 행렬 곱)\n",
    "- 가중합한 것임  (밸류 텐서에 행렬 곱으로 반영)\n",
    "\n",
    "이번 강의에서는 글자단위 토크나이저 쓰니까\n",
    "\n",
    "예를 들자면\n",
    "\n",
    "- `쿼리`: 난 모음인데 나랑 있는 자음은 누구니\n",
    "- `키`: 내가 자음이야\n",
    "    - 해당 키를 가진 토큰이 가장 유사도 점수가 높음\n",
    "- `밸류`: 실제 토큰에 쓰일 값\n",
    "    - 여기다 가중합(행렬곱)으로 반영\n",
    "\n",
    "해당 태스크에 필요한 정보들을 서로 문답하면서(communication)\n",
    "\n",
    "토큰마다 최적의 hidden state를 찾는 것\n",
    "\n",
    "## note 2: 어텐션에는 위치 정보(timestep)에 대한 정보가 없음\n",
    "\n",
    "그래서 **positional encoding**이 필요함\n",
    "\n",
    "어텐션은 그냥 임베딩 벡터 집합 내에 유사도 행렬을 구하고 밸류 텐서에 반영하는 것뿐이라 timestep 정보가 없음\n",
    "\n",
    "## note 3: 각 미니 배치끼리는 communicate하지 않음\n",
    "\n",
    "뭐… 당연한거죠?\n",
    "\n",
    "셀프 어텐션은 각 미니 배치 내 토큰(timestep)끼리 계산\n",
    "\n",
    "각 미니 배치는 독립적으로 수행 → GPU로 병렬처리 ㄱㄴ\n",
    "\n",
    "## note 4: encoder block인 경우 마스킹(tril) 없음\n",
    "\n",
    "학습할 때 얘기임 추론이 아니라 \n",
    "\n",
    "디코더는 NLG(자연어 생성)가 원래 목적이라\n",
    "\n",
    "다음 스텝에 올 토큰을 예측함\n",
    "\n",
    "근데 다음 토큰에 관한 정보가 있으면 컨닝하는 거라 마스킹(tril)하는 거\n",
    "\n",
    "인코더는 원래 목적이 NLU(자연어 이해)라서\n",
    "\n",
    "셀프 어텐션할 때 모든 인풋 시퀀스를 고려함\n",
    "\n",
    "마스킹이 필요없음\n",
    "\n",
    "tril 적용 부분 주석 처리하면 됨\n",
    "\n",
    "## note 5: cross-attention은 쿼리, 키/밸류의 소스가 다름\n",
    "\n",
    "셀프 어텐션은 쿼리, 키, 밸류가 모두 같은 소스임\n",
    "\n",
    "우리가 구현한 거 보면 모두 인풋 `x`로부터 `nn.Linear` 통과한 텐서들\n",
    "\n",
    "하지만 크로스 어텐션인 경우 소스가 다름\n",
    "\n",
    "예를 들어 `attention is all you need` 논문을 보면\n",
    "\n",
    "인코더-디코더 모델을 쓰는데 (트랜스포머 아키텍처)\n",
    "`쿼리`는 인풋 `x`가 소스고\n",
    "\n",
    "`키/밸류`는 인코더 모듈 출력임\n",
    "\n",
    "## note 6: 왜 쿼리-키 행렬곱한걸 sqrt(d_k)로 나눌까?\n",
    "\n",
    "`attention is all you need` 논문 보면\n",
    "\n",
    "어텐션 점수 구할 때 쿼리 키 행렬 곱을 스케일링함\n",
    "\n",
    "$$\n",
    "Attention=\\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}V\\right)\n",
    "$$\n",
    "\n",
    "여기서 $d_k$는 헤드 내 텐서 차원 수 (=$d_{model}/\\#\\ of\\ head$)\n",
    "\n",
    "### 학습하기 전에는 틀린 가중치를 가짐\n",
    "\n",
    "맨 처음 모델 initialization하면 학습되지 않은 상태\n",
    "\n",
    "이때 추론시키면 정답이 아닌 다른 카테고리 확률이 높음 → loss 큼\n",
    "\n",
    "마찬가지로 학습하기 전에 쿼리-키 행렬곱하면 \n",
    "\n",
    "밸류에 대한 틀린 가중치를 갖게 됨\n",
    "\n",
    "### 쿼리-키 행렬 곱하면서 분산이 커짐\n",
    "\n",
    "$QK^T$하면서 대략 $d_k$만큼 분산이 커짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8743306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0877), tensor(1.0594), tensor(18.4436))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "q = torch.randn(B, T, head_dim) # 4, 8, 16\n",
    "k = torch.randn(B, T, head_dim)\n",
    "wei = q @ k.transpose(-2, -1)\n",
    "\n",
    "q.var(), k.var(), wei.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edce78a",
   "metadata": {},
   "source": [
    "wei의 분산이 18이나 커짐ㄷㄷ\n",
    "\n",
    "분산이 크면 결국 softmax 취했을 때 균등하지 않고 극단적이게 됨 (원핫 벡터에 가까워짐)\n",
    "\n",
    "예를 들어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f07c081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03349c15",
   "metadata": {},
   "source": [
    "분산을 키우면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b10ae8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e988c3",
   "metadata": {},
   "source": [
    "학습 첫 스텝에서는 잘못된 추론으로\n",
    "\n",
    "큰 loss를 가질 수밖에 없음\n",
    "\n",
    "그러므로 kaiming initialization처럼 std gain을 보상해주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3727096b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0877), tensor(1.0594), tensor(1.1527))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "q = torch.randn(B, T, head_dim)\n",
    "k = torch.randn(B, T, head_dim)\n",
    "wei = q @ k.transpose(-2, -1) / head_dim**0.5\n",
    "\n",
    "q.var(), k.var(), wei.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e76306",
   "metadata": {},
   "source": [
    "# Layer normalization\n",
    "\n",
    "배치 정규화랑 달리 각 row 방향으로 (피처 방향)으로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfbe618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm:\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        xmean = x.mean(1, keepdim=True)\n",
    "        xvar = x.var(1, keepdim=True)\n",
    "        xhat = (x- xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1425cd2",
   "metadata": {},
   "source": [
    "# 데이터 살펴보기\n",
    "\n",
    "mini shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf89a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us\n"
     ]
    }
   ],
   "source": [
    "with open('../mini_shakes.txt', 'r', encoding='utf8') as fp:\n",
    "    text = fp.read()\n",
    "\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f838ce",
   "metadata": {},
   "source": [
    "# 토큰화\n",
    "\n",
    "이전에 해왔던 대로 그냥 한글자 단위로 vocab 설정\n",
    "\n",
    "**토크나이저 vocab 사이즈** vs **timestep trade off**\n",
    "\n",
    "vocab 사이즈가 작은 걸로 토큰화하면 time step(context window) 커집니다.\n",
    "\n",
    "요즘은 영어인 경우 다 BPE나 titoken 써가지고 vocab size 좀 큽니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677c023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8deac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encode('hii there'))\n",
    "print(decode(encode('hii there')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ae807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9355e4c",
   "metadata": {},
   "source": [
    "# train/val split\n",
    "\n",
    "셰익스피어를 완벽히 암기하는게 아니라 셰익스피어같이 텍스트 생성하는 게 목표\n",
    "\n",
    "오버피팅도 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3540f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6938b2a3",
   "metadata": {},
   "source": [
    "# block size만큼 데이터 범위 설정\n",
    "\n",
    "**block size: 학습할 때의 최대 context window**\n",
    "\n",
    "(다음 토큰을 예측하기 직전의 토큰 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa9644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target: 47\n",
      "when input is tensor([18, 47]) the target: 56\n",
      "when input is tensor([18, 47, 56]) the target: 57\n",
      "when input is tensor([18, 47, 56, 57]) the target: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3806713f",
   "metadata": {},
   "source": [
    "블록 수만큼 학습\n",
    "\n",
    "블록 크기가 8개라면 위처럼 8개의 학습 데이터가 만들어집니다.\n",
    "\n",
    "이렇게 하면 모델이 매우 작은 컨텍스트(=1)부터 최대 컨텍스트(=8)까지 모두 학습할 수 있습니다.\n",
    "\n",
    "→ 다양한 인풋에 적절한 답변 생성할 수 있게 됩니다. (인풋 길이 작아도, 커도 대답!)\n",
    "\n",
    "이제 배치 4로 해서 만들어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea1afcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----\n",
      "when input is [24] the target: 43\n",
      "when input is [24, 43] the target: 58\n",
      "when input is [24, 43, 58] the target: 5\n",
      "when input is [24, 43, 58, 5] the target: 57\n",
      "when input is [24, 43, 58, 5, 57] the target: 1\n",
      "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
      "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
      "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
      "when input is [44] the target: 53\n",
      "when input is [44, 53] the target: 56\n",
      "when input is [44, 53, 56] the target: 1\n",
      "when input is [44, 53, 56, 1] the target: 58\n",
      "when input is [44, 53, 56, 1, 58] the target: 46\n",
      "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
      "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
      "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52] the target: 58\n",
      "when input is [52, 58] the target: 1\n",
      "when input is [52, 58, 1] the target: 58\n",
      "when input is [52, 58, 1, 58] the target: 46\n",
      "when input is [52, 58, 1, 58, 46] the target: 39\n",
      "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
      "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
      "when input is [25] the target: 17\n",
      "when input is [25, 17] the target: 27\n",
      "when input is [25, 17, 27] the target: 10\n",
      "when input is [25, 17, 27, 10] the target: 0\n",
      "when input is [25, 17, 27, 10, 0] the target: 21\n",
      "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
      "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
      "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cd9052",
   "metadata": {},
   "source": [
    "# loss 측정 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c9d01cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b79fa5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embed = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bceccc9",
   "metadata": {},
   "source": [
    "# [optional] bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "32b7e2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B, T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T) # targets.view(-1)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the prediction\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "88c677ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "65b00919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pytorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e8dbb30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss: 4.729425430297852\n",
      "step 5000 loss: 2.5123085975646973\n",
      "step 10000 loss: 2.4576165676116943\n",
      "step 15000 loss: 2.442767381668091\n",
      "step 20000 loss: 2.4573700428009033\n",
      "step 25000 loss: 2.4389965534210205\n",
      "step 30000 loss: 2.4534378051757812\n",
      "step 35000 loss: 2.4459445476531982\n",
      "step 40000 loss: 2.463813543319702\n",
      "step 45000 loss: 2.456265926361084\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(50000):\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps%5000==0:\n",
    "        print('step', steps, 'loss:', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d517ccea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HAs; n og ARKEve tous oone ntanthintis n Thimed;\n",
      "Houchy me t ckin by mapa, owis.\n",
      "Andean she dva\n",
      "Age f:\n",
      "\n",
      "An t br'rtrercad locheres.\n",
      "I oly I t onddorint biss be ceed vemmy I ngowhinothabld\n",
      "tat hel I ompatyor yo t.\n",
      "IIORIIN s, ir Bewilf sof ate k suser s y usprgr!\n",
      "TUKiler igerindsolle CESIOFormegine s f pr's meany ghiele.\n",
      "ORe man thethes smme t hen ffrend t whickitho.\n",
      "f o n h s lewr ny atheeerklour, a\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76bac20",
   "metadata": {},
   "source": [
    "# GPTLanguageModel(nn.Module)\n",
    "우리가 최종적으로 만들고 싶은 언어 생성 모델!\n",
    "\n",
    "메서드 단위로 쪼개서 보자\n",
    "\n",
    "## `def __init__(self)`\n",
    "\n",
    "- `토큰 임베딩 테이블`\n",
    "- `포지셔널 임베딩(인코딩) 테이블`\n",
    "    - 원 논문에서는 sinusoidal로 했지만 여기서는 그냥 임베딩 모델로 함\n",
    "- `트랜스포머 디코더 block들`\n",
    "    - 여기 있는 Block은 뒤에서 만들도록 하겠음\n",
    "- `layer normalization`\n",
    "- `lm_head`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d9814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.positional_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed, n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8797da",
   "metadata": {},
   "source": [
    "## `def _init_weights(self, module)`\n",
    "\n",
    "특이하게도 가중치 초기화 메서드를 따로 적용함\n",
    "\n",
    "가중치의 경우 평균 0, std 0.02 정규분포로 초기화!\n",
    "\n",
    "편향은 0으로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e21be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.positional_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed, n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "        # better init\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00586096",
   "metadata": {},
   "source": [
    "## `def forward(self, idx, targets)`\n",
    "\n",
    "1. `토큰 임베딩`\n",
    "2. `포지셔널 임베딩`도 더해서 추가\n",
    "3. 모든 `트랜스포머 디코더 블록` 통과\n",
    "4. `레이어 정규화`\n",
    "5. `lm_head` 거쳐서 `logits` 계산\n",
    "6. `targets`가 주어진 경우 `cross entropy loss` 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.positional_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed, n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "        # better init\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B, T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, C)\n",
    "        pos_emb = self.positional_embedding_table(torch.arange(T, device=device)) # (T, C)\n",
    "        x = tok_emb + pos_emb # (B, T, C)\n",
    "        x = self.blocks(x) # (B, T, C)\n",
    "        x = self.ln_f(x) # (B, T, C)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf05a8",
   "metadata": {},
   "source": [
    "## `def generate(self, idx, max_new_tokens)`\n",
    "\n",
    "주어진 `max_new_tokens` 만큼 계속 토큰 생성할 거임\n",
    "\n",
    "1. `idx_cond`로 데이터가 `block_size` 만 있도록 남김\n",
    "    1. 모델은 `block_size`만큼만 인풋으로 받을 수 있기 때문!\n",
    "2. 모델 추론으로 `logits`, `loss` 구함\n",
    "3. 다음 토큰 확률만 궁금하니 최종 timestep에 대한 `logits`만 남김\n",
    "4. `F.softmax`로 다음 토큰 확률 구함\n",
    "5. `torch.multinomial`로 다음 토큰 뽑음\n",
    "6. 생성된 토큰 데이터에 `torch.cat`해서 끝에 붙임\n",
    "\n",
    "반복 반복!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3a5612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.positional_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed, n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "        # better init\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B, T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, C)\n",
    "        pos_emb = self.positional_embedding_table(torch.arange(T, device=device)) # (T, C)\n",
    "        x = tok_emb + pos_emb # (B, T, C)\n",
    "        x = self.blocks(x) # (B, T, C)\n",
    "        x = self.ln_f(x) # (B, T, C)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ad3fe3",
   "metadata": {},
   "source": [
    "# class Block\n",
    "\n",
    "핵심 부분을 만들자\n",
    "\n",
    "## `def __init__(self, n_embed, n_head)`\n",
    "\n",
    "그림에서 볼 수 있듯이\n",
    "\n",
    "- `멀티 헤드 어텐션`\n",
    "- `레이어 정규화`\n",
    "- `피드포워드`\n",
    "\n",
    "가 필요함\n",
    "\n",
    "`head_size`는 가 헤드가 담당하는 차원 수!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "830ea4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication follwed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c62b8ae",
   "metadata": {},
   "source": [
    "## `def forward(self, x)`\n",
    "\n",
    "그림처럼 `셀프 어텐션` 후 `피드포워드`에 넘기면 됨!\n",
    "\n",
    "residual connection도 적용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a728bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication follwed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd1fad",
   "metadata": {},
   "source": [
    "원 논문 그림을 보면\n",
    "\n",
    "- `셀프 어텐션` 후에 `레이어 정규화`\n",
    "- `피드포워드` 후에 `레이어 정규화`\n",
    "\n",
    "이렇게 하는데 슨상님은 좋지 않다고 생각\n",
    "\n",
    "배치 정규화랑 마찬가지로 `레이어 정규화`도\n",
    "\n",
    "`행렬 곱`과 `활성화 함수` 때메 바뀌는 `std`를 미리 최적으로 잡아주는 용도임\n",
    "\n",
    "그러므로 `행렬 곱`과 `활성화 함수` 전에 적용하는 것이 맞다고 생각\n",
    "\n",
    "# class FeedForward\n",
    "\n",
    "매우 간단\n",
    "\n",
    "원 논문 식이랑 똑같이 감\n",
    "\n",
    "$$\n",
    "FFN(x) = max(0,\\  xW_1 + b_1)W_2 + b2 \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c52e3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity\"\"\"\n",
    "\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4*n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbda92",
   "metadata": {},
   "source": [
    "# class MultiHeadAttention\n",
    "\n",
    "## `def __init__(self, num_heads, head_size)`\n",
    "\n",
    "딱 그림처럼\n",
    "\n",
    "- `여러 어텐션 헤드`\n",
    "- `proejction layer`\n",
    "- `드롭아웃`도 추가…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "327abad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel\"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size*num_heads, n_embed) # (n_embed, n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500af2e7",
   "metadata": {},
   "source": [
    "잘보면 어텐션 헤드는 `nn.Sequential`이 아니라 `ModuleList`임!\n",
    "\n",
    "Sequential은 말그대로 순차적으로 `x1 → module1 → x2 → module2` 이렇게 가는거고\n",
    "\n",
    "여기서는 순차적이 아닌 동시에 써서 `concat` 할거라 `nn.ModuleList` 씀\n",
    "\n",
    "## `def forward(self, x)`\n",
    "\n",
    "그림처럼\n",
    "\n",
    "1. 모든 어텐션 헤드 결과값 `torch.cat`\n",
    "2. `projection(Linear) layer` 통과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2e6d7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel\"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size*num_heads, n_embed) # (n_embed, n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5595ebb",
   "metadata": {},
   "source": [
    "# class Head\n",
    "\n",
    "위에서 만든 헤드 쓰면 됨\n",
    "\n",
    "- `쿼리, 키, 밸류`\n",
    "- 마스킹을 위해 `tril`\n",
    "    - `register_buffer`인 이유는 파라미터를 가진 게 아닌데 그냥 클래스 변수로 만들고 싶어서 그럼\n",
    "- `드롭아웃`도 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e273bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention\"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input size ---> (Batch, Timestep, Channels)\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        q = self.query(x) # (B, T, head_size)\n",
    "        k = self.key(x) # (B, T, head_size)\n",
    "\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5 # (B,T,T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B,T,T)\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B, T, head_size)\n",
    "        out = wei @ v # (B,T,T) @ (B,T,head_size) ---> (B,T, head_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df5865",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f0d9a932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.788929 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = GPTLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e02624c",
   "metadata": {},
   "source": [
    "colab T4로 54분 걸렸습니다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c68371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pytorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval==0 or iter==max_iters-1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c7693",
   "metadata": {},
   "source": [
    "# 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
